
### **MAGI 系统架构蓝图 (SAB v2.0)**

#### **一、核心设计哲学**

1.  **AI 即服务 (Agent-as-a-Service)**: 每个 AI 代理都是一个独立的、无状态的微服务。它们只负责自己的核心逻辑（如角色扮演、情节生成），不保存长期记忆。
2.  **中心化状态与无状态代理 (Centralized State & Stateless Agents)**: 系统的“记忆”被剥离出来，由一个专门的“共享状态管理器”（数据库和缓存）统一管理。AI 代理在每次执行任务时，按需从状态管理器获取上下文，完成任务后将结果交由编排器写回。这使得代理可以被轻松替换、扩展和负载均衡。
3.  **事件驱动与命令查询分离**: 系统的状态变化通过事件（Events）来广播和记录（如“角色A移动到了新东京”）。而代理的调用则是明确的命令（Commands）或查询（Queries）。

#### **二、高层系统架构图**

这是一个典型的微服务架构，清晰地划分了职责。

```
+--------------------------------------------------------------------------------------------------+
|                                    用户 (通过 Web/桌面 App)                                      |
+------------------------------------+-------------------------------------------------------------+
                                     | (HTTPS, WebSocket)
+------------------------------------v-------------------------------------------------------------+
|                                      API 网关 (API Gateway)                                      |
|                             (处理认证、请求限流、路由到内部服务)                                 |
+------------------------------------+-------------------------------------------------------------+
                                     | (RESTful API / gRPC 调用)
+------------------------------------v-------------------------------------------------------------+
|                                      任务编排器 (Task Orchestrator)                              |
|                                    (核心业务逻辑、路由管理、工作流引擎)                          |
+--+---------------------------------+---------------------------+----------------------------------+
   | (1. 解析指令)                     | (2. 查询上下文)           | (4. 执行任务)                  | (6. 更新状态)
   |                                 |                           |                                |
   v                                 v                           v                                v
+--------------------------+    +--------------------------+    +--------------------------+    +--------------------------+
|  LLM 网关 & 模型管理器   |    |  共享状态管理器          |    |  AI 代理服务集群        |<---|  事件总线 (Event Bus)    |
| (统一管理对不同LLM的调用)|    | (Shared State Manager)   |    | (Agent Service Cluster)  |    | (如 Kafka, RabbitMQ)   |
| - OpenAI, Anthropic      |    | - PostgreSQL (主数据)    |    | - 世界引擎 (Service A)   |    +--------------------------+
| - 本地模型 (Ollama)      |    | - Vector DB (记忆/文档)  |    | - 情节引擎 (Service B)   |
+--------------------------+    | - Redis (缓存/会话)      |    | - 角色引擎 (Service C)   |
                              +--------------------------+    | - ... 等其他引擎         |
                                                            +--------------------------+
```

#### **三、代理 (Agent) 的边界定义**

这是系统的核心。每个代理都是一个拥有明确**输入-处理-输出**边界的专家。

| **代理名称** | **核心职责 (边界定义)** | **输入 (API Contract)** | **输出 (API Contract)** | **依赖的服务/数据** |
| :--- | :--- | :--- | :--- | :--- |
| **世界引擎** | **世界观的守护者和信息源**。负责：<br>1. 回答关于世界设定的查询。<br>2. 检查给定文本是否与已知设定冲突。 | `POST /query` Body: `{ "query_text": "新东京市的天气？" }`<br><br>`POST /check_consistency` Body: `{ "text_to_check": "主角搓了个火球..." }` | `{ "status": "success", "data": "新东京常年下酸雨..." }`<br><br>`{ "is_consistent": false, "reason": "当前世界为无魔设定。" }` | 向量数据库 (世界圣经) |
| **情节引擎** | **故事的驱动者 (DM)**。负责：<br>1. 根据导演指令生成场景描述。<br>2. 创造非预期的转折或事件。 | `POST /narrate` Body: `{ "directive": "主角躲进仓库", "context": "..." }` | `{ "narrative_chunk": "黑暗的仓库里堆满了生锈的集装箱..." }` | 共享状态管理器 (获取最近事件上下文) |
| **角色引擎** | **角色的扮演者 (Actor)**。负责：<br>1. 根据角色设定和当前情景，生成行动、对话或独白。 | `POST /act` Body: `{ "character_id": "char_001", "situation": "你被包围了", "context": "..." }` | `{ "character_name": "凯恩", "output_type": "dialogue", "content": "看起来我们有麻烦了。" }` | PostgreSQL (角色卡), 共享状态管理器 (角色当前状态) |
| **书记官引擎**<br>(Scribe Engine) | **被动的记忆记录者**。负责：<br>1. **监听**事件总线。<br>2. 将所有生成的文本和事件结构化地存入数据库。 | *(不直接接收API调用)*<br>监听事件总线上的 `story_updated` 事件。 | *(不产生直接输出)*<br>将结构化数据写入 PostgreSQL 和向量数据库。 | 事件总线 |
| **润色引擎**<br>(Prose Engine) | **文笔优化专家**。负责：<br>1. 改进给定文本的语言风格。<br>2. 统一全文的语调。 | `POST /polish` Body: `{ "text": "他跑得很快。", "style_guide": "赛博朋克冷峻风格" }` | `{ "polished_text": "他在霓虹光影中化作一道模糊的残像。" }` | (无核心依赖) |

#### **四、链接方式、路由管理与实现模式**

1.  **链接方式 (Connection Method)**:
    *   **外部 -> 内部**: 客户端（Web App）通过 **HTTPS (RESTful API)** 与 **API网关** 通信，用于执行主要命令。同时，可以通过 **WebSocket** 建立长连接，用于实时接收AI生成过程中的流式输出或系统通知。
    *   **内部服务间**: 服务之间优先使用高性能的 **gRPC** 或轻量级的 **RESTful API** 进行同步通信。例如，编排器向情节引擎发出一个生成场景的指令。

2.  **路由管理 (Route Management)**:
    *   **API 网关**: 负责将外部请求路由到正确的内部服务，主要是**任务编排器**。例如，`/api/v1/project/123/act` 会被路由到编排器的 `handle_act_command` 方法。
    *   **任务编排器 (核心路由)**: 这是真正的“大脑”。它不执行AI任务，而是**决定调用哪个AI代理，以及调用的顺序**。它是一个**工作流引擎**。
        *   **示例工作流 (`act` 命令)**:
            1.  接收到 `act` 命令 `{ "character_id": "char_001", "situation": "你被包围了" }`。
            2.  向**共享状态管理器**查询，获取最近的5条故事事件作为 `context`。
            3.  向**共享状态管理器**查询 `char_001` 的角色卡和当前状态。
            4.  组装请求，向**角色引擎服务**的 `/act` 端口发起调用。
            5.  接收到角色引擎的响应。
            6.  将响应包装成一个 `story_updated` 事件，发布到**事件总线**。
            7.  `书记官引擎` 监听到该事件，并将其异步地写入数据库。
            8.  将响应返回给 API 网关，最终呈现给用户。

3.  **实现的模式 (Implementation Patterns)**:
    *   **微服务架构**: 每个代理、每个核心组件（编排器、状态管理器）都是一个可以独立部署、扩展和更新的服务。这为系统带来了极高的灵活性和可维护性。
    *   **编排器模式 (Orchestrator Pattern)**: 我们使用一个中心化的“编排器”来管理复杂的工作流，而不是让服务之间自由混乱地相互调用（所谓的“合唱模式”）。这使得业务逻辑清晰可控。
    *   **LLM 代理模式 (LLM Agent Pattern)**: 每个 AI 代理内部都遵循一个 **"思考-工具-行动" (ReAct, Chain-of-Thought)** 的循环。例如，“角色引擎”在决定行动前，可以内部决定是否需要调用“工具”（如向世界引擎查询信息），然后再生成最终行动。
    *   **Command Query Responsibility Segregation (CQRS) - 精神**: 虽然不完全实现，但我们的设计借鉴了其核心思想。**写操作**（生成新内容）通过 `Commands` 触发，并通过 `Events` 记录状态变更。**读操作**（查询世界观、获取故事上下文）则是独立的 `Queries`。这使得数据读写可以被分别优化。
    *   **LLM 网关 (LLM Gateway)**: 这是一个至关重要的模式。所有对底层大模型（OpenAI, Anthropic 等）的调用都必须通过这个网关。好处是：
        *   **统一接口**: 替换或增加新模型对上层代理透明。
        *   **成本控制**: 可以在此层做统一的缓存、日志记录和预算控制。
        *   **安全**: API 密钥被集中管理，不会泄露到各个业务服务中。


#### **结论**

这份架构蓝图 v2.0 真正将 MAGI 系统从一个脚本提升到了一个企业级的分布式应用。它通过明确的边界定义和服务拆分，解决了可扩展性、可维护性和健壮性的问题。

**我们现在拥有了一个真正的开发路线图：**

1.  **第一步**: 搭建基础架构，包括 API 网关、空的编排器服务以及数据库。
2.  **第二步**: 实现 `LLM 网关` 和 `共享状态管理器`，这是所有服务的基础。
3.  **第三步**: 逐一开发并部署**世界引擎**、**情节引擎**和**角色引擎**这三个核心的 AI 代理服务。
4.  **第四步**: 实现**事件总线**和**书记官引擎**，让系统拥有持久的记忆。
5.  **第五步**: 开发前端应用，与 API 网关对接，完成整个闭环。

