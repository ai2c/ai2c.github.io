<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark_colorblind" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='https://blog.meekdai.com/Gmeek/plugins/GmeekTOC.js'></script><script src='https://blog.meekdai.com/Gmeek/plugins/lightbox.js'></script><script src='https://blog.meekdai.com/Gmeek/plugins/GmeekVercount.js'></script>
    <link rel="icon" href="https://ai2c.github.io/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="### **MAGI 系统架构蓝图 (SAB v2.1)**

**版本历史**:
*   **v2.0**: 提出了一个理想化的、面向服务的微服务架构。">
<meta property="og:title" content="MAGI系统的设想3：一个用于长篇叙事生成的协作式多智能体框架 #6">
<meta property="og:description" content="### **MAGI 系统架构蓝图 (SAB v2.1)**

**版本历史**:
*   **v2.0**: 提出了一个理想化的、面向服务的微服务架构。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ai2c.github.io/post/MAGI-xi-tong-de-she-xiang-3%EF%BC%9A-yi-ge-yong-yu-chang-pian-xu-shi-sheng-cheng-de-xie-zuo-shi-duo-zhi-neng-ti-kuang-jia-%20%236.html">
<meta property="og:image" content="https://ai2c.github.io/avatar.svg">
<title>MAGI系统的设想3：一个用于长篇叙事生成的协作式多智能体框架 #6</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>
<style>body { font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif; } .post-item { transition: all 0.3s ease; } .post-item:hover { transform: translateY(-2px); box-shadow: 0 8px 24px rgba(0,0,0,0.12); }</style>



<body>
    <div id="header">
<h1 class="postTitle">MAGI系统的设想3：一个用于长篇叙事生成的协作式多智能体框架 #6</h1>
<div class="title-right">
    <a href="https://ai2c.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/ai2c/ai2c.github.io/issues/7" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h3><strong>MAGI 系统架构蓝图 (SAB v2.1)</strong></h3>
<p><strong>版本历史</strong>:</p>
<ul>
<li><strong>v2.0</strong>: 提出了一个理想化的、面向服务的微服务架构。</li>
<li><strong>v2.1</strong>: 在 v2.0 的基础上，根据工程实践进行修正。引入了务实的、从单体到微服务的演进路线图，明确了 LLM 网关和 Embedding 的核心设计，并修正了工作流。</li>
</ul>
<h4><strong>一、核心设计哲学</strong></h4>
<ol>
<li><strong>AI 即服务 (Agent-as-a-Service)</strong>: 每个 AI 功能单元（引擎）都被视为一个独立的“专家服务”，拥有清晰的职责边界。</li>
<li><strong>中心化状态与无状态代理 (Centralized State &amp; Stateless Agents)</strong>: AI 代理本身不存储长期记忆。所有项目数据、世界观、故事内容等“状态”由一个共享状态管理器统一维护，代理在执行任务时按需获取上下文。</li>
<li><strong>务实演进 (Pragmatic Evolution)</strong>: 系统架构并非一成不变。我们将从一个功能完备的<strong>单体应用 (Monolith)</strong> 开始，快速验证核心价值，然后根据业务增长和性能需求，逐步、平滑地将关键模块重构为<strong>微服务 (Microservices)</strong>。</li>
</ol>
<h4><strong>二、架构演进路线图</strong></h4>
<p>我们不一步到位实现最终架构，而是分阶段演进。</p>
<p><strong>阶段一：脊梁 (The Spine - V0.1)</strong><br>
此阶段的目标是<strong>最快速度打通核心功能闭环</strong>。我们采用单体应用架构，所有逻辑都在一个服务中。</p>
<p align="center">
    <b>架构图 V0.1: 单体优先</b>
</p>
<p align="center">
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0cd59dacba46531efc0481d50d40329a83f915415e29eed33fb646ebad24dbda/68747470733a2f2f692e696d6775722e636f6d2f7854746b5230392e706e67"><img src="https://camo.githubusercontent.com/0cd59dacba46531efc0481d50d40329a83f915415e29eed33fb646ebad24dbda/68747470733a2f2f692e696d6775722e636f6d2f7854746b5230392e706e67" alt="MAGI Spine V0.1 Architecture" width="700" data-canonical-src="https://i.imgur.com/xTtkR09.png" style="max-width: 100%;"></a>
</p>
<ul>
<li><strong>描述</strong>: 一个基于 Python FastAPI 的后端服务。内部模块化，但部署在一起。
<ul>
<li><strong>API Layer</strong>: 负责接收前端HTTP请求。</li>
<li><strong>Orchestrator Logic</strong>: 简单的函数调用，负责串联 <code class="notranslate">Engines</code> 和 <code class="notranslate">Database</code>。</li>
<li><strong>LLM Gateway</strong>: 内部模块，负责与外部AI API通信。</li>
<li><strong>Engines</strong>: 以 Python 类的形式存在。</li>
<li><strong>Database</strong>: 使用本地 SQLite 文件进行快速启动，并内嵌一个本地向量数据库（如 ChromaDB）。</li>
</ul>
</li>
</ul>
<p><strong>阶段二：愿景 (The Vision - V2.0+)</strong><br>
当系统经过验证、用户量增长、功能变得复杂时，我们将向 v2.0 的微服务架构迁移。</p>
<p align="center">
    <b>架构图 V2.0+: 理想微服务架构</b>
</p>
```
+--------------------------------------------------------------------------------------------------+
|                                    用户 (通过 Web/桌面 App)                                      |
+------------------------------------+-------------------------------------------------------------+
                                     | (HTTPS, WebSocket)
+------------------------------------v-------------------------------------------------------------+
|                                      API 网关 (API Gateway)                                      |
+------------------------------------+-------------------------------------------------------------+
                                     | (RESTful API / gRPC 调用)
+------------------------------------v-------------------------------------------------------------+
|                                      任务编排器 (Task Orchestrator)                              |
+--+-------------------+---------------+-----------------------+---------------------+---------------+
   | 1.解析指令          | 2.查询上下文    | 3.选择代理并准备调用    | 4.执行任务        | 5.接收结果    | 6.更新状态
   |                   |               |                       |                   |               |
   v                   v               v                       v                   v               v
+------------------+ +-----------------+ +---------------------+ +-----------------+ +-------------+  +----------------+
| (自身逻辑)       | | 共享状态管理器    | | (自身逻辑)            | | AI 代理服务集群   | | (自身逻辑)    |  | 事件总线       |
|                  | | - PostgreSQL      | |                     | | - 世界引擎        | |             |  | (如 Kafka)   |
|                  | | - Vector DB       | |                     | | - 情节引擎        | |             |  +----------------+
|                  | | - Redis           | |                     | | ...             | |             |
+------------------+ +-----------------+ +---------------------+ +-------+---------+ +-------------+
                                                                         |
                                                                         v
                                                                  +---------------+
                                                                  | LLM 网关      |
                                                                  +---------------+
```
<hr>
<h4><strong>三、核心组件详细设计</strong></h4>
<ol>
<li>
<p><strong>LLM 网关 (LLM Gateway)</strong></p>
<ul>
<li><strong>职责</strong>: 作为系统与所有外部大语言模型（LLM）API通信的<strong>唯一出口</strong>。</li>
<li><strong>实现模式</strong>: <strong>适配器模式 (Adapter Pattern)</strong>。定义一个统一的内部接口（<code class="notranslate">LLMProvider</code>），然后为每个外部服务（OpenAI, Gemini, Anthropic等）实现一个具体的适配器类。</li>
<li><strong>核心功能</strong>:
<ul>
<li><strong>统一接口</strong>: 提供 <code class="notranslate">generate(prompt)</code> 和 <code class="notranslate">embed(text)</code> 等标准方法，上层业务逻辑无需关心底层模型的差异。</li>
<li><strong>凭证管理</strong>: 集中、安全地管理所有 API 密钥。</li>
<li><strong>模型切换</strong>: 可以通过配置轻松切换默认模型，或为不同任务指定不同模型。</li>
<li><strong>成本与监控</strong>: 统一记录调用日志、计算 token 消耗，为成本控制和性能监控提供数据。</li>
<li><strong>重试与回退</strong>: 内置请求重试和熔断机制。例如，当一个模型API失败时，可以自动尝试另一个备用模型。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>共享状态管理器 &amp; Embedding</strong></p>
<ul>
<li><strong>职责</strong>: 系统的“记忆中枢”，负责所有数据的持久化存储和检索。</li>
<li><strong>组件</strong>:
<ul>
<li><strong>关系型数据库 (PostgreSQL/SQLite)</strong>: 存储结构化数据，如项目信息、用户账户、故事章节的元数据、角色卡片等。</li>
<li><strong>向量数据库 (ChromaDB/Faiss/Pinecone)</strong>: <strong>【核心组件】</strong> 存储通过 Embedding 生成的向量数据。</li>
</ul>
</li>
<li><strong>Embedding 的核心作用 (RAG)</strong>: 这是 MAGI 实现智能的关键。
<ul>
<li><strong>写入时</strong>: 当任何“知识”被添加到系统时（如世界观条目、故事段落），会立即通过 LLM 网关的 <code class="notranslate">embed()</code> 方法将其转换为向量，并存入向量数据库。</li>
<li><strong>读取/生成时</strong>: 当AI需要生成内容时，系统会执行以下 <strong>RAG (Retrieval-Augmented Generation)</strong> 流程：
<ol>
<li><strong>检索 (Retrieve)</strong>: 将用户的当前指令或问题进行 Embedding，然后在向量数据库中进行语义搜索，找出最相关的 N 条“知识”（可能是世界观、可能是过去的情节）。</li>
<li><strong>增强 (Augment)</strong>: 将检索到的这些知识片段，格式化后作为“上下文”插入到最终要发送给 LLM 的 Prompt 中。</li>
<li><strong>生成 (Generate)</strong>: LLM 基于这个被“增强”了的、信息丰富的 Prompt 生成内容，从而保证了内容的一致性和深度。</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>AI 代理服务 (AI Agent Services)</strong><br>
每个引擎都是一个拥有明确 API 的专家。在单体架构中是类，在微服务架构中是独立服务。</p>
<ul>
<li><strong>世界引擎</strong>: 提供 <code class="notranslate">query(text)</code> 和 <code class="notranslate">check_consistency(text)</code> 接口。其内部实现严重依赖向量数据库。</li>
<li><strong>情节引擎</strong>: 提供 <code class="notranslate">narrate(directive, context)</code> 接口。它接收导演指令和 RAG 检索到的上下文，然后调用 LLM 网关生成场景。</li>
<li><strong>角色引擎</strong>: 提供 <code class="notranslate">act(character_id, situation, context)</code> 接口。它会先从 SQL 数据库加载角色卡，结合 RAG 上下文，调用 LLM 网关进行角色扮演。</li>
</ul>
</li>
<li>
<p><strong>任务编排器 (Task Orchestrator)</strong></p>
<ul>
<li><strong>职责</strong>: 业务逻辑的核心，负责响应 API 请求，并按照预定工作流调度其他组件。它是“导演的大脑”。</li>
<li><strong>核心工作流示例 (<code class="notranslate">/narrate</code> 指令)</strong>:
<ol>
<li><strong>接收请求</strong>: API 层接收到 <code class="notranslate">POST /project/123/narrate</code>，请求体为 <code class="notranslate">{ "directive": "主角走进了酒吧" }</code>。</li>
<li><strong>上下文检索 (RAG)</strong>:<br>
a. 调用 LLM 网关将 <code class="notranslate">"主角走进了酒吧"</code> 这句话 <code class="notranslate">embed()</code> 成向量。<br>
b. 使用该向量去<strong>向量数据库</strong>中查询最相关的3条世界观/记忆片段（例如：“这个酒吧叫‘锈蚀扳手’，是黑客的据点”、“主角正在被‘公司’追捕”）。<br>
c. 从 <strong>SQL 数据库</strong>中查询最近的5条故事记录。</li>
<li><strong>Prompt 组装</strong>: 将原始指令、检索到的世界观、最近的故事记录组合成一个高质量的 Prompt。</li>
<li><strong>调用引擎</strong>: 调用<strong>情节引擎</strong>的 <code class="notranslate">narrate</code> 方法，传入组装好的 Prompt。</li>
<li><strong>接收结果</strong>: 引擎通过 <strong>LLM 网关</strong> 返回生成的故事文本。</li>
<li><strong>持久化状态</strong>:<br>
a. 将新生成的故事文本作为一个 <code class="notranslate">StoryChunk</code> 存入 <strong>SQL 数据库</strong>。<br>
b. （异步）将这个新的文本块进行 <code class="notranslate">embed()</code> 并存入<strong>向量数据库</strong>，使其成为未来可供检索的“记忆”。</li>
<li><strong>返回响应</strong>: 将生成的故事文本返回给前端。</li>
</ol>
</li>
</ul>
</li>
</ol>
<hr>
<h4><strong>四、建设规划与线路图 (Actionable Roadmap)</strong></h4>
<ol>
<li>
<p><strong>Phase 1: 脊梁 (V0.1) - 目标：1周内上线可用原型</strong></p>
<ul>
<li><strong>任务</strong>:
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 使用 FastAPI 搭建单体应用框架。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 实现 <code class="notranslate">LLM Gateway</code>，至少支持 OpenAI 或 Gemini 两者之一。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 实现使用 SQLite 的 <code class="notranslate">Database</code> 模块（仅需 <code class="notranslate">Project</code> 和 <code class="notranslate">StoryChunk</code> 表）。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 实现一个基础的<strong>情节引擎</strong>。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 实现 <code class="notranslate">/narrate</code> 和 <code class="notranslate">/story</code> 两个核心 API。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 使用 React/Vue 搭建一个极简的前端页面，能调用上述 API 并展示结果。</li>
</ul>
</li>
<li><strong>验收标准</strong>: 用户可以在网页上输入指令，看到 AI 生成的故事，刷新页面后故事内容依然存在。</li>
</ul>
</li>
<li>
<p><strong>Phase 2: 大脑 (V0.2) - 目标：引入 RAG</strong></p>
<ul>
<li><strong>任务</strong>:
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 在项目中集成 ChromaDB（一个内嵌式向量数据库）。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 在 <code class="notranslate">LLM Gateway</code> 中完善 <code class="notranslate">embed()</code> 方法的实现。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 增加用于管理世界观的 API (<code class="notranslate">/world_bible</code>)。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 改造 <code class="notranslate">/narrate</code> 工作流，<strong>正式引入 RAG 流程</strong>：在生成前先从向量数据库检索上下文。</li>
</ul>
</li>
<li><strong>验收标准</strong>: 添加世界观设定后，AI 的生成内容能明显体现出这些设定，故事一致性显著提高。</li>
</ul>
</li>
<li>
<p><strong>Phase 3: 血肉 (V0.3+) - 目标：功能扩展</strong></p>
<ul>
<li><strong>任务</strong>:
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 实现<strong>角色引擎</strong>和相关的 API。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 实现<strong>润色引擎</strong>等辅助工具。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 优化前端界面，支持多项目管理、角色卡编辑等。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 根据性能瓶颈，考虑将 <strong>LLM 网关</strong> 或消耗最高的引擎作为第一个微服务拆分出去。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Phase 4: 愿景 (V2.0+) - 目标：全面微服务化</strong></p>
<ul>
<li><strong>任务</strong>:
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 将数据库迁移到独立的 PostgreSQL 和专用向量数据库服务。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 逐步将所有引擎拆分为独立的微服务。</li>
<li class="task-list-item"><input type="checkbox" id="" disabled="" class="task-list-item-checkbox" aria-label="Incomplete task"> 引入 API 网关和事件总线，实现最终的架构蓝图。</li>
</ul>
</li>
</ul>
</li>
</ol></div>
<div style="font-size:small;margin-top:8px;float:right;">✨ 感谢阅读 | 转载无需注明出处</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://ai2c.github.io">流光拾萤录</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("09/04/2025"!=""){
    var startSite=new Date("09/04/2025");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","ai2c/ai2c.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>


</html>
